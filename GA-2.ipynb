{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer to graded assignment 2 in DTE-2501 (AI Methods and Applications) about ensemble methods by Abdullah Karag√∏z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from math import pi\n",
    "from math import exp\n",
    "from math import log\n",
    "from math import fsum\n",
    "import platform\n",
    "platform.architecture()\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "dataset = pd.read_csv('iris.data', header=None, names=['sepal length', 'sepal width',\n",
    "                                                     'petal length', 'petal width',\n",
    "                                                     'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign label to each class\n",
    "dataset.loc[dataset['class'] == 'Iris-setosa', dataset.columns == 'class'] = 0\n",
    "dataset.loc[dataset['class'] == 'Iris-versicolor', dataset.columns == 'class'] = 1\n",
    "dataset.loc[dataset['class'] == 'Iris-virginica', dataset.columns == 'class'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "class NaiveBayesClassifier():\n",
    "    \"\"\"\n",
    "    This is a class for classification using Gaussian Naive Bayes classification where attributes\n",
    "    are numerical.\n",
    "      \n",
    "    Attributes:\n",
    "        train_set (Pandas Dataframe): the training dataset means, stds and other values are based on\n",
    "        mean_values (list): contains mean values of all attributes for each class.\n",
    "        std_values (list): contains standard deviation values of all attribtuets for each class\n",
    "        prior_class_probabilities (list): contains prior class probabilities for each class\n",
    "        nr_of_classes (int): number of classes the dataset has\n",
    "        nr_of_attributes (int): number of attributes (columns) the dataset has\n",
    "        proba (list): probabilities of the prediction from test set\n",
    "        preds (list): predictions from test set\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializing the NaiveBayesClassifier.\n",
    "        \"\"\"\n",
    "        self.train_set = list()\n",
    "        self.__mean_values = list()\n",
    "        self.__std_values =  list()\n",
    "        self.__prior_class_probabilities =  list()\n",
    "        self.__nr_of_classes = 0\n",
    "        self.__nr_of_attributes = 0\n",
    "        self.__proba = list()\n",
    "        self.__preds = list()\n",
    "        self.__trained = False # Trained flag\n",
    "        \n",
    "    def fit(self, train_set):\n",
    "        \"\"\"\n",
    "        Training the classifier.\n",
    "        \n",
    "        Initializing mean values, std values, prior probabilites, number of classes and attributes.\n",
    "        \n",
    "        Parameters:\n",
    "            train_set (Pandas Dataframe): training samples where classes are \n",
    "                integers starting from 0, saved under column named 'class'.\n",
    "        \"\"\"\n",
    "        self.train_set = train_set\n",
    "        \n",
    "        # if not in ensemble, we calculate these values\n",
    "        self.__nr_of_classes=train_set.groupby('class').ngroups\n",
    "        self.__nr_of_attributes=len(train_set.iloc[0,:-1])\n",
    "        \n",
    "        # Here we keep mean, std and prior class probability values\n",
    "        self.__mean_values = list()\n",
    "        self.__std_values = list()\n",
    "        self.__prior_class_probs = list()\n",
    "        \n",
    "        # calculating mean, std values and prior probabilities\n",
    "        for i in range(self.__nr_of_classes):\n",
    "            class_values = train_set[train_set['class'] == i]\n",
    "            prior_class_prob = len(class_values) / len(train_set)\n",
    "            self.__prior_class_probs.append(prior_class_prob)\n",
    "            mean_values = list()\n",
    "            std_values = list()   \n",
    "            for j in range(self.__nr_of_attributes):\n",
    "                values = class_values.iloc[:,j].values.tolist()\n",
    "                std, mean = self.__std_and_mean(values)\n",
    "                mean_values.append(mean)\n",
    "                std_values.append(std)\n",
    "            self.__mean_values.append(mean_values)\n",
    "            self.__std_values.append(std_values)\n",
    "        \n",
    "        self.__trained = True\n",
    "\n",
    "\n",
    "    def __mean(self, val_list):\n",
    "        \"\"\"\n",
    "        Getting the mean of the values.\n",
    "        \n",
    "        Parameters:\n",
    "            val_list (int): list of values.\n",
    "        \n",
    "        returns:\n",
    "            float: mean of the values.\n",
    "        \"\"\"\n",
    "        return fsum(val_list) / len(val_list)\n",
    "    \n",
    "    def __std_and_mean(self, val_list):\n",
    "        \"\"\"\n",
    "        Getting the mean and standard deviation of the values\n",
    "        \n",
    "        Parameters:\n",
    "            val_list (int): list of values\n",
    "        \n",
    "        returns:\n",
    "            (float, float): standard deviation and mean of the values\n",
    "        \"\"\"\n",
    "        mu = self.__mean(val_list)\n",
    "        std = sqrt(fsum([(x - mu)**2 for x in val_list]) / (len(val_list)-1))\n",
    "        return std, mu\n",
    "        \n",
    "    \n",
    "    def __gaussian_pdf(self, x, mu, sd, log_prob):\n",
    "        \"\"\"\n",
    "        Calculating the probability with Gaussian PDF.\n",
    "        \n",
    "        Parameters:\n",
    "            x (float): the value to claculated probability of with Gaussian PDF\n",
    "            mu (float): mean value to be used in Gaussian PDF\n",
    "            sd (float): standard devaition value to be used in Gaussian PDF\n",
    "            log_prob (bool): set to True to use logarithm of the probability in claculations.\n",
    "        \n",
    "        Returns:\n",
    "            (float): the probability value of x using Gaussian PDF.    \n",
    "        \"\"\"\n",
    "        if log_prob:\n",
    "            return_val = (-0.5*((x-mu)/sd)**2) - log(sd*sqrt(2*pi))\n",
    "        else:\n",
    "            return_val = (1 / (sd*sqrt(2*pi))) * exp(-0.5*((x-mu)/sd)**2)\n",
    "        return return_val\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Predicting classes on the test set\n",
    "    def predict(self, test_set, log_prob = False):\n",
    "        \"\"\"\n",
    "        Predicts the class of all samples in a test set\n",
    "        \n",
    "        Parameters:\n",
    "            test_set (Pandas Dataframe): samples to be tested, where the class is in the last column, and\n",
    "                other columns contain attribute values.\n",
    "            log_prob (bool): set to True if you want to use logarithm of probabilities in calculations.\n",
    "            \n",
    "        Returns:\n",
    "            list: predicted class labels.\n",
    "        \"\"\"\n",
    "        if not self.__trained:\n",
    "            raise Exception(\"The classifier is not trained yet, run fit() function by passing the training set.\")\n",
    "        probabilities = self.predict_proba(test_set, log_prob)\n",
    "        \n",
    "        self.__preds = [probs.index(max(probs)) for probs in probabilities]\n",
    "        \n",
    "        return self.__preds\n",
    "\n",
    "    \n",
    "    \n",
    "    # Predicting probabilities of the test set\n",
    "    def predict_proba(self, test_set, log_prob=False):\n",
    "        \"\"\"\n",
    "        Compute the probabilities of classes of all samples in a test set\n",
    "        \n",
    "        Parameters:\n",
    "            test_set (Pandas Dataframe): samples to be tested, where the class is in the last column, and\n",
    "                other columns contain attribute values.\n",
    "            log_prob (bool): set to True if you want to use logarithm of probabilities in calculations.\n",
    "            \n",
    "        Returns:\n",
    "            list: weighted average probability for each class per sample.\n",
    "        \"\"\"\n",
    "        if not self.__trained:\n",
    "            raise Exception(\"The classifier is not trained yet, run fit() function by passing the training set.\")\n",
    "        X_test = test_set.iloc[:, :-1].values.tolist()\n",
    "        y_test = test_set.iloc[:, -1].values.tolist()\n",
    "        self.__y_test = y_test\n",
    "        \n",
    "        probabilities = list()\n",
    "        for x, y in zip(X_test, y_test):\n",
    "            prob = self.probs_row(x, log_prob)\n",
    "            probabilities.append(prob)\n",
    "        self.__proba = probabilities\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    \n",
    "    def get_proba():\n",
    "        \"\"\"\n",
    "        Get the computed probabilities cache\n",
    "        \"\"\"\n",
    "        if self.__proba:\n",
    "            return self.__proba\n",
    "        else:\n",
    "            raise Exception(\"The probabilities are empty\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    def probs_row(self, row, log_prob = False):\n",
    "        \"\"\"\n",
    "        Compute the probability of class for each sample.\n",
    "        \n",
    "        Parameters:\n",
    "            row (list): a list of attributes of the class, all attributes must be numerical.\n",
    "            log_prob (bool): Set to True if you want to use logarithm of probabilities in calculations.\n",
    "        Returns:\n",
    "            list: weighted probabilities of each label.\n",
    "        \"\"\"\n",
    "        probs = self.__nr_of_classes*[0]\n",
    "        if log_prob:\n",
    "            for i in range(self.__nr_of_classes):\n",
    "                probs[i] = 0 if self.__prior_class_probs[i] == 0 else log(self.__prior_class_probs[i])\n",
    "                for j in range(len(row)):\n",
    "                    probs[i] += self.__gaussian_pdf(row[j], self.__mean_values[i][j], self.__std_values[i][j], log_prob)\n",
    "                probs[i] = exp(probs[i])\n",
    "        \n",
    "        else: \n",
    "            for i in range(self.__nr_of_classes):\n",
    "                probs[i] = self.__prior_class_probs[i]\n",
    "                for j in range(len(row)):\n",
    "                    probs[i] *= self.__gaussian_pdf(row[j], self.__mean_values[i][j], self.__std_values[i][j], log_prob)\n",
    "        probs = [x / fsum(probs) for x in probs]\n",
    "        return probs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembled Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembledNBClassifier():  \n",
    "    \"\"\"\n",
    "    This is a class for classification using by ensembling Gaussian Naive Bayes classifiers where attributes\n",
    "    are numerical. It's using bagging method.\n",
    "    \n",
    "    Attributes:\n",
    "        classifiers (list): where all NaiveBayesClassifier objects are kept\n",
    "        proba (list): probabilities of the prediction from test set\n",
    "        preds (list): predictions from test set\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, nr_of_classifiers):\n",
    "        \"\"\"\n",
    "        Initializing the NaiveBayesClassifier.\n",
    "        \n",
    "        Parameters:\n",
    "            nr_of_classifiers (int): number of classifiers which the ensemble method will have.\n",
    "        \"\"\"\n",
    "        self.classifiers = list()\n",
    "        for i in range(nr_of_classifiers):\n",
    "            self.classifiers.append(NaiveBayesClassifier())\n",
    "        self.__proba = list()\n",
    "        self.__preds = list()\n",
    "        self.__trained = False # Trained flag\n",
    "    \n",
    "    \n",
    "    def fit(self, train_set, seed=None):\n",
    "        \"\"\"\n",
    "        Training all classifiers.\n",
    "        \n",
    "        Initializing mean values, std values, prior probabilites, number of classes and attributes.\n",
    "        \n",
    "        Parameters:\n",
    "            train_set (Pandas Dataframe): training samples where classes are \n",
    "                integers starting from 0, saved under column named 'class'.\n",
    "        \"\"\"\n",
    "        # Initializing classifiers\n",
    "        for cl in self.classifiers:\n",
    "            bag = train_set.sample(frac=1, replace=True, random_state=seed).reset_index(drop=True)\n",
    "            cl.fit(bag)\n",
    "        \n",
    "        self.__trained = True\n",
    "    \n",
    "        \n",
    "    \n",
    "    def predict(self, test_set, log_prob = False, majority_vote = False):\n",
    "        \"\"\"\n",
    "        Predicts the class of all samples in a test set using aggregated value or majoriy voting.\n",
    "        \n",
    "        Parameters:\n",
    "            test_set (Pandas Dataframe): samples to be tested, where the class is in the last column, and\n",
    "                other columns contain attribute values.\n",
    "            log_prob (bool): set to True if you want to use logarithm of probabilities in calculations.\n",
    "            majority_vote (bool): set to True if you want to use majority voting in prediction.\n",
    "            \n",
    "        Returns:\n",
    "            list: predicted class labels.\n",
    "        \"\"\"\n",
    "        if  not self.__trained:\n",
    "            raise Exception(\"The classifier is not trained yet, run fit() function by passing the training set.\")\n",
    "        \n",
    "        predictions = list()\n",
    "        \n",
    "        if majority_vote:\n",
    "            all_probs = self.__get_all_probs(test_set, log_prob)\n",
    "            for probs in all_probs:\n",
    "                preds = [prob.index(max(prob)) for prob in probs]\n",
    "                pred = max(set(preds), key = lambda x: preds.count(x) + 0.1*random.random())\n",
    "                predictions.append(pred)\n",
    "        \n",
    "        else:\n",
    "            agg_probs = self.predict_proba(test_set, log_prob)\n",
    "            predictions = [probs.index(max(probs)) for probs in agg_probs]\n",
    "        \n",
    "        self.__preds = predictions\n",
    "        return self.__preds\n",
    "            \n",
    "\n",
    "    \n",
    "    def predict_proba(self, test_set, log_prob = False):\n",
    "        \"\"\"\n",
    "        Compute the probabilities of classes of all samples in a test set, using aggregated value.\n",
    "        \n",
    "        Parameters:\n",
    "            test_set (Pandas Dataframe): samples to be tested, where the class is in the last column, and\n",
    "                other columns contain attribute values.\n",
    "            log_prob (bool): set to True if you want to use logarithm of probabilities in calculations.\n",
    "            \n",
    "        Returns:\n",
    "            list: weighted average probability for each class per sample.\n",
    "        \"\"\"\n",
    "        if not self.__trained:\n",
    "            raise Exception(\"The classifier is not trained yet, run fit() function by passing the training set.\")\n",
    "        \n",
    "        all_probs = self.__get_all_probs(test_set, log_prob)\n",
    "        \n",
    "        \n",
    "        probabilities = list()\n",
    "        \n",
    "        for probs in all_probs:\n",
    "            # Arithmetic mean of all probabilities\n",
    "            agg_probs = [fsum(x)/len(probs) for x in zip(*probs)]\n",
    "            probabilities.append(agg_probs)\n",
    "\n",
    "        self.__proba = probabilities\n",
    "        return self.__proba\n",
    "    \n",
    "    \n",
    "    def __get_all_probs(self, test_set, log_prob):\n",
    "        \"\"\"\n",
    "        A helper function to get all weighted average probability for each \n",
    "        class per sample for each classifier.\n",
    "        \n",
    "        Parameters:\n",
    "            test_set (Pandas Dataframe): samples to be tested, where the class is in the last column, and\n",
    "                other columns contain attribute values.\n",
    "                \n",
    "            log_prob (bool): set to True if you want to use logarithm of probabilities in calculations.\n",
    "            \n",
    "        Returns:\n",
    "            list: weighted average probability for each class per sample for each classifier.\n",
    "        \"\"\"\n",
    "        # splitting the data\n",
    "        X_test = test_set.iloc[:, :-1].values.tolist()\n",
    "        y_test = test_set.iloc[:, -1].values.tolist()\n",
    "        \n",
    "        all_probs = list()\n",
    "        \n",
    "        for x, y in zip(X_test, y_test):\n",
    "            preds = list()\n",
    "            probs = list()\n",
    "\n",
    "            for cl in self.classifiers:\n",
    "                prob = cl.probs_row(x, log_prob) # predict each row\n",
    "                probs.append(prob)\n",
    "            \n",
    "            all_probs.append(probs)\n",
    "        return all_probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics class (static functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    \"\"\"\n",
    "    This is a class to compute performace metrics of classifiers. \n",
    "    It has only static functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def get_cel(y_true, y_proba):\n",
    "        \"\"\"\n",
    "        Computing Cross Entropy Loss\n",
    "        \n",
    "        Parameters:\n",
    "            y_true (list): desired values from test set.\n",
    "            y_proba (list): weighted average probability for each class per sample.\n",
    "            \n",
    "        Returns:\n",
    "            float: Cross Entropy Loss value\n",
    "        \"\"\"\n",
    "        cel = 0\n",
    "        for probs, y in zip(y_proba, y_true):\n",
    "            cel -= log(probs[y])\n",
    "        \n",
    "        return cel\n",
    "    \n",
    "    \n",
    "    def get_accuracy(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Computing accuracy\n",
    "        \n",
    "        Parameters:\n",
    "            y_true (list): desired values from test set.\n",
    "            y_proba (list): weighted average probability for each class per sample.\n",
    "            \n",
    "        Returns:\n",
    "            float: Accuracy value.\n",
    "        \"\"\"\n",
    "        corrects = 0\n",
    "        for pred, y in zip(y_pred, y_true):\n",
    "            corrects += (int(y == pred))\n",
    "        \n",
    "        accuracy = corrects / len(y_true)\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def get_f1(y_true, y_pred, labels, average='macro'):\n",
    "        \"\"\"\n",
    "        Computing F1 score\n",
    "        \n",
    "        Parameters:\n",
    "            y_true (list): desired values from test set.\n",
    "            y_proba (list): weighted average probability for each class per sample.\n",
    "            labels (int): How many labels does the class have\n",
    "            average: set to 'macro' to return mean F1 score, 'micro' to return F1 score for each class.\n",
    "            \n",
    "        Returns:\n",
    "            float or list: mean F1 score or F1 score for each class\n",
    "        \"\"\"\n",
    "        precisions = labels*[0]\n",
    "        recalls = labels*[0]\n",
    "        f1 = labels*[0]\n",
    "        tp = labels*[0] # True positives\n",
    "        tn = labels*[0] # True negatives\n",
    "        fn = labels*[0] # False negatives\n",
    "        fp = labels*[0] # False positives\n",
    "        \n",
    "        # Calculating TP, TN, FP, FN\n",
    "        for pred, y in zip(y_pred, y_true):\n",
    "            for i in range(labels):\n",
    "                if i == pred:\n",
    "                    if pred == y:\n",
    "                        tp[i] += 1\n",
    "                    else:\n",
    "                        fp[i] += 1\n",
    "                elif i != pred:\n",
    "                    if pred == y:\n",
    "                        fn[i] += 1\n",
    "                    else:\n",
    "                        tn[i] += 1\n",
    "        # Calculating F1 scores\n",
    "        for i in range(labels):\n",
    "            precisions[i] = tp[i] / (tp[i] + fp[i])\n",
    "            recalls[i] = tp[i] / (tp[i] + fn[i])\n",
    "            f1[i] = (2*precisions[i]*recalls[i]) /  (precisions[i]+recalls[i])\n",
    "        \n",
    "        if average=='macro': # Return mean f1\n",
    "            mean_f1 = fsum(f1)/labels\n",
    "            return mean_f1\n",
    "        else:\n",
    "            return f1 # Return f1 for all classes\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing n times and see average f1, accuracy and cel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from tabulate import tabulate\n",
    "\n",
    "n = 10 # Nr of tests to make\n",
    "nr_of_classifiers = 10\n",
    "train_test_split = 0.8\n",
    "\n",
    "def testing(dataset, nr_of_classifiers = 10, tarin_test_split = 0.8, n=10, seed=False):\n",
    "    nr_of_classes = dataset.groupby('class').ngroups\n",
    "\n",
    "    # All will be list of 3 lists, each of sub-list will be for accyracy, F1 and Cel.\n",
    "    tests_single_skl = [[] for i in range(3)]\n",
    "    tests_single = [[] for i in range(3)]\n",
    "    tests_single_log = [[] for i in range(3)]\n",
    "\n",
    "    tests_ensemble_skl = [[] for i in range(3)]\n",
    "    tests_ensemble_voting = [[] for i in range(3)]\n",
    "    tests_ensemble_aggr = [[] for i in range(3)]\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "        # Shuffle and split data into training 80% and testing 20%\n",
    "        train_set = dataset.sample(frac=train_test_split, random_state=seed)\n",
    "        test_set = dataset.drop(train_set.index)\n",
    "        train_set.reset_index(drop=True, inplace=True)\n",
    "        test_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        y_true = test_set.iloc[:,-1].values.tolist()\n",
    "\n",
    "        # Prepare the Numpy array which will be used in Sklearn libraries\n",
    "        X_train = train_set.iloc[:,:-1].to_numpy()\n",
    "        y_train = train_set.iloc[:,-1].to_numpy().astype('int')\n",
    "        X_test = test_set.iloc[:,:-1].to_numpy()\n",
    "        y_test = test_set.iloc[:,-1].to_numpy().astype('int')\n",
    "\n",
    "        # From Sci-kit learn\n",
    "        nbc = GaussianNB()\n",
    "        nbc.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = nbc.predict(X_test)\n",
    "        Y_proba = nbc.predict_proba(X_test)\n",
    "\n",
    "        tests_single_skl[0].append(Metrics.get_accuracy(y_true, y_pred))\n",
    "        tests_single_skl[1].append(Metrics.get_f1(y_true, y_pred, nr_of_classes))\n",
    "        tests_single_skl[2].append(Metrics.get_cel(y_true, Y_proba))\n",
    "\n",
    "\n",
    "        # Single classifier initialize\n",
    "        nbc = NaiveBayesClassifier()\n",
    "        nbc.fit(train_set)\n",
    "\n",
    "        # Single classifier without using log\n",
    "        y_pred = nbc.predict(test_set)\n",
    "        Y_proba = nbc.predict_proba(test_set)\n",
    "\n",
    "        tests_single[0].append(Metrics.get_accuracy(y_true, y_pred))\n",
    "        tests_single[1].append(Metrics.get_f1(y_true, y_pred, nr_of_classes))\n",
    "        tests_single[2].append(Metrics.get_cel(y_true, Y_proba))\n",
    "\n",
    "\n",
    "        # Single classifier with using log\n",
    "        y_pred = nbc.predict(test_set, log_prob=True)\n",
    "        Y_proba = nbc.predict_proba(test_set, log_prob=True)\n",
    "\n",
    "        tests_single_log[0].append(Metrics.get_accuracy(y_true, y_pred))\n",
    "        tests_single_log[1].append(Metrics.get_f1(y_true, y_pred, nr_of_classes))\n",
    "        tests_single_log[2].append(Metrics.get_cel(y_true, Y_proba))\n",
    "\n",
    "\n",
    "        # Initializing and training ensemble of Sci-kit Learn\n",
    "        ens_nbc = BaggingClassifier(GaussianNB(), n_estimators=nr_of_classifiers, random_state=seed)\n",
    "        ens_nbc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = ens_nbc.predict(X_test)\n",
    "        Y_proba = ens_nbc.predict_proba(X_test)\n",
    "\n",
    "        tests_ensemble_skl[0].append(Metrics.get_accuracy(y_true, y_pred))\n",
    "        tests_ensemble_skl[1].append(Metrics.get_f1(y_true, y_pred, nr_of_classes))\n",
    "        tests_ensemble_skl[2].append(Metrics.get_cel(y_true, Y_proba))\n",
    "\n",
    "\n",
    "        #Initializing and training ensemble classifier I built\n",
    "        ens_nbc = EnsembledNBClassifier(nr_of_classifiers)\n",
    "        ens_nbc.fit(train_set, seed)\n",
    "\n",
    "        # Ensembled classifier using majority vote\n",
    "        y_pred = ens_nbc.predict(test_set, majority_vote = True)\n",
    "\n",
    "        tests_ensemble_voting[0].append(Metrics.get_accuracy(y_true, y_pred))\n",
    "        tests_ensemble_voting[1].append(Metrics.get_f1(y_true, y_pred, nr_of_classes))\n",
    "\n",
    "        # Ensembled classifier using aggregated probabilities\n",
    "        y_pred = ens_nbc.predict(test_set)\n",
    "        Y_proba = ens_nbc.predict_proba(test_set)\n",
    "\n",
    "        tests_ensemble_aggr[0].append(Metrics.get_accuracy(y_true, y_pred))\n",
    "        tests_ensemble_aggr[1].append(Metrics.get_f1(y_true, y_pred, nr_of_classes))\n",
    "        tests_ensemble_aggr[2].append(Metrics.get_cel(y_true, Y_proba))\n",
    "\n",
    "    # Calculating means from the lists\n",
    "\n",
    "    mean_results = [[] for x in range(6)]\n",
    "\n",
    "\n",
    "    mean_results[0].append('Single classifier Sklearn')\n",
    "    mean_results[1].append('Single classifier')\n",
    "    mean_results[2].append('Single classifier with log prob')\n",
    "    mean_results[3].append('Ensemble classifier Sklearn')\n",
    "    mean_results[4].append('Ensemble classifier with majority voting')\n",
    "    mean_results[5].append('Ensemble classifier with aggreated probabilities')\n",
    "\n",
    "    for i in range(3):\n",
    "        mean_results[0].append(fsum(tests_single_skl[i]) / n)\n",
    "        mean_results[1].append(fsum(tests_single[i]) / n)\n",
    "        mean_results[2].append(fsum(tests_single_log[i]) / n)\n",
    "        mean_results[3].append(fsum(tests_ensemble_skl[i]) / n)\n",
    "        mean_results[4].append(fsum(tests_ensemble_voting[i]) / n)\n",
    "        mean_results[5].append(fsum(tests_ensemble_aggr[i]) / n)\n",
    "    \n",
    "    mean_results[4][3] = ('N/A')\n",
    "\n",
    "    comparison_table = tabulate(mean_results, \n",
    "                                headers=['Accuracy', 'F1 Score', 'Cross Entropy Loss'], floatfmt=\".4f\")\n",
    "    \n",
    "#     df = pd.DataFrame(mean_results, \n",
    "#                                 columns=['Classifier', 'Accuracy', 'F1 Score', 'Cross Entropy Loss'])\n",
    "    \n",
    "#     display(df)\n",
    "    print(comparison_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "\n",
    "def plotting_ensemble(dataset, nr_of_classifiers, train_test_split, seed):\n",
    "    # Shuffle and split data into training 80% and testing 20%\n",
    "    train_set = dataset.sample(frac=train_test_split, random_state=seed)\n",
    "    test_set = dataset.drop(train_set.index)\n",
    "    train_set.reset_index(drop=True, inplace=True)\n",
    "    test_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    y_true = test_set.iloc[:,-1].values.tolist()\n",
    "\n",
    "    # Prepare the Numpy array which will be used in Sklearn libraries\n",
    "    X_train = train_set.iloc[:,:-1].to_numpy()\n",
    "    y_train = train_set.iloc[:,-1].to_numpy().astype('int')\n",
    "    X_test = test_set.iloc[:,:-1].to_numpy()\n",
    "    y_test = test_set.iloc[:,-1].to_numpy().astype('int')\n",
    "\n",
    "\n",
    "    f1_results = [[] for i in range(3)]\n",
    "    cel_results = [[] for i in range(3)]\n",
    "    acc_results = [[] for i in range(3)]\n",
    "    \n",
    "    for n in range(1, nr_of_classifiers+1):\n",
    "        # Initializing and training ensemble of Sci-kit Learn\n",
    "        ens_nbc = BaggingClassifier(GaussianNB(), n_estimators=n, random_state=seed)\n",
    "        ens_nbc.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = ens_nbc.predict(X_test)\n",
    "        Y_proba = ens_nbc.predict_proba(X_test)\n",
    "\n",
    "        acc_results[0].append(Metrics.get_accuracy(y_true, y_pred))\n",
    "        f1_results[0].append(Metrics.get_f1(y_true, y_pred, nr_of_classes))\n",
    "        cel_results[0].append(Metrics.get_cel(y_true, Y_proba))\n",
    "\n",
    "\n",
    "        #Initializing and training ensemble classifier I built\n",
    "        ens_nbc = EnsembledNBClassifier(n)\n",
    "        ens_nbc.fit(train_set, seed)\n",
    "\n",
    "        # Ensembled classifier using majority vote\n",
    "        y_pred = ens_nbc.predict(test_set, majority_vote = True)\n",
    "\n",
    "        acc_results[1].append(Metrics.get_accuracy(y_true, y_pred))\n",
    "        f1_results[1].append(Metrics.get_f1(y_true, y_pred, nr_of_classes))\n",
    "\n",
    "\n",
    "        # Ensembled classifier using aggregated probabilities\n",
    "        y_pred = ens_nbc.predict(test_set)\n",
    "        Y_proba = ens_nbc.predict_proba(test_set)\n",
    "\n",
    "        acc_results[2].append(Metrics.get_accuracy(y_true, y_pred))\n",
    "        f1_results[2].append(Metrics.get_f1(y_true, y_pred, nr_of_classes))\n",
    "        cel_results[2].append(Metrics.get_cel(y_true, Y_proba))\n",
    "        \n",
    "    width = 0.25\n",
    "    x_ticks = [x+1 for x in range(nr_of_classifiers)]\n",
    "    x_1 = [x+1 for x in range(nr_of_classifiers)]\n",
    "    x_2 = [x+1+width for x in range(nr_of_classifiers)]\n",
    "    x_3 = [x+1+width*2 for x in range(nr_of_classifiers)]\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    \n",
    "    # Create 2x2 sub plots\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.bar(x_1, acc_results[0], width=width, label='Sklearn')\n",
    "    ax1.bar(x_2, acc_results[1], width=width, label='Majority voting')\n",
    "    ax1.bar(x_3, acc_results[2], width=width, label='Aggregation')\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_xlabel(\"Nr of estimators\")\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "    ax1.grid()\n",
    "\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.bar(x_1, f1_results[0], width=width, label='Sklearn')\n",
    "    ax2.bar(x_2, f1_results[1], width=width, label='Majority voting')\n",
    "    ax2.bar(x_3, f1_results[2], width=width, label='Aggregation')\n",
    "    ax2.set_ylabel(\"F1 score\")\n",
    "    ax2.set_xlabel(\"Nr of estimators\")\n",
    "    ax2.set_title(\"F1 score\")\n",
    "    ax2.grid()\n",
    "\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    ax3.bar(x_1, cel_results[0], width=width, label='Sklearn')\n",
    "    ax3.bar(x_2, cel_results[2], width=width, label='Aggregation')\n",
    "    ax3.set_ylabel(\"CEL\")\n",
    "    ax3.set_xlabel(\"Nr of estimators\")\n",
    "    ax3.set_title(\"Cross Entropy Loss\")\n",
    "    ax3.grid()\n",
    "    \n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, bbox_to_anchor=(0.5, 0.1, 0.1, 0.4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.suptitle('Performance of ensemble methods', fontsize=16)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Accuracy    F1 Score  Cross Entropy Loss\n",
      "------------------------------------------------  ----------  ----------  --------------------\n",
      "Single classifier Sklearn                             0.9333      0.4780  3.366501902356016\n",
      "Single classifier                                     0.9333      0.4780  3.3688197590123496\n",
      "Single classifier with log prob                       0.9333      0.4780  3.368819759012351\n",
      "Ensemble classifier Sklearn                           0.9667      0.4868  2.5794428979675046\n",
      "Ensemble classifier with majority voting              0.9333      0.4780  N/A\n",
      "Ensemble classifier with aggreated probabilities      0.9333      0.4780  3.4527288298889043\n"
     ]
    }
   ],
   "source": [
    "nr_of_tests = 1 # Nr of tests to make\n",
    "nr_of_classifiers = 10\n",
    "train_test_split = 0.8\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "\n",
    "testing(dataset, nr_of_classifiers, train_test_split, nr_of_tests, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotting_ensemble(dataset, nr_of_classifiers, train_test_split, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
