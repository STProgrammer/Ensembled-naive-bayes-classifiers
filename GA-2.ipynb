{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer to graded assignment 2 in DTE-2501 (AI Methods and Applications) about ensemble methods by Abdullah Karagøz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from math import pi\n",
    "from math import exp\n",
    "from math import log\n",
    "from math import fsum\n",
    "import platform\n",
    "platform.architecture()\n",
    "import random\n",
    "\n",
    "seed = None\n",
    "\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "dataset = pd.read_csv('iris.data', header=None, names=['sepal length', 'sepal width',\n",
    "                                                     'petal length', 'petal width',\n",
    "                                                     'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign label to each class\n",
    "dataset.loc[dataset['class'] == 'Iris-setosa', dataset.columns == 'class'] = 0\n",
    "dataset.loc[dataset['class'] == 'Iris-versicolor', dataset.columns == 'class'] = 1\n",
    "dataset.loc[dataset['class'] == 'Iris-virginica', dataset.columns == 'class'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width class\n",
       "0             5.7          2.8           4.5          1.3     1\n",
       "1             6.4          2.8           5.6          2.1     2\n",
       "2             5.7          3.0           4.2          1.2     1\n",
       "3             6.7          3.1           4.7          1.5     1\n",
       "4             5.0          2.3           3.3          1.0     1\n",
       "..            ...          ...           ...          ...   ...\n",
       "115           4.9          3.1           1.5          0.1     0\n",
       "116           6.4          3.2           5.3          2.3     2\n",
       "117           4.4          3.2           1.3          0.2     0\n",
       "118           5.4          3.9           1.7          0.4     0\n",
       "119           5.1          3.5           1.4          0.3     0\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[train_set['class']==0].iloc[:,0].values.tolist()\n",
    "\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "class NaiveBayesClassifier():\n",
    "    def __init__(self):\n",
    "        self.dataset = 0\n",
    "        self.mean_values = 0\n",
    "        self.std_values = 0\n",
    "        self.prior_class_probabilities = 0\n",
    "        self.nr_of_classes = 0\n",
    "        self.nr_of_attributes = 0\n",
    "        \n",
    "    def fit(self, train_set, in_ensemble=False, nr_of_classes = 0,\n",
    "            nr_of_attributes=0):\n",
    "        self.dataset = train_set\n",
    "        \n",
    "        # calculating mean, std values and prior probabilities\n",
    "        \n",
    "        # if not in ensemble, we calculate these values\n",
    "        if not in_ensemble:\n",
    "            self.nr_of_classes=train_set.groupby('class').ngroups\n",
    "            self.nr_of_attributes=len(train_set.iloc[0,:-1])\n",
    "        else:\n",
    "            self.nr_of_classes = nr_of_classes\n",
    "            self.nr_of_attributes = nr_of_attributes\n",
    "        \n",
    "        # Here we keep mean, std and prior class probability values\n",
    "        self.mean_values = list()\n",
    "        self.std_values = list()\n",
    "        self.prior_class_probs = list()\n",
    "        \n",
    "        for i in range(self.nr_of_classes):\n",
    "            class_values = train_set[train_set['class'] == i]\n",
    "            prior_class_prob = len(class_values) / len(train_set)\n",
    "            self.prior_class_probs.append(prior_class_prob)\n",
    "            mean_values = list()\n",
    "            std_values = list()   \n",
    "            for j in range(self.nr_of_attributes):\n",
    "                values = class_values.iloc[:,j].values.tolist()\n",
    "                std, mean = self.std_and_mean(values)\n",
    "                mean_values.append(mean)\n",
    "                std_values.append(std)\n",
    "            self.mean_values.append(mean_values)\n",
    "            self.std_values.append(std_values)\n",
    "\n",
    "\n",
    "    def mean(self, val_list):\n",
    "        return sum(val_list) / len(val_list)\n",
    "    \n",
    "    def std_and_mean(self, val_list):\n",
    "        mu = self.mean(val_list)\n",
    "        std = sqrt(fsum([(x - mu)**2 for x in val_list]) / (len(val_list)-1))\n",
    "        return std, mu\n",
    "        \n",
    "    \n",
    "    def gaussian_pdf(self, x, mu, sd, log_prob):\n",
    "        if log_prob:\n",
    "            return_val = (-0.5*((x-mu)/sd)**2) - log(sd*sqrt(2*pi))\n",
    "        else:\n",
    "            return_val = (1 / (sd*sqrt(2*pi))) * exp(-0.5*((x-mu)/sd)**2)\n",
    "        return return_val\n",
    "    \n",
    "    \n",
    "    def pred_row(self, row, log_prob = False):\n",
    "        probs = self.nr_of_classes*[0]\n",
    "        if log_prob:\n",
    "            for i in range(self.nr_of_classes):\n",
    "                probs[i] = 0 if self.prior_class_probs[i] == 0 else log(self.prior_class_probs[i])\n",
    "                for j in range(len(row)):\n",
    "                    probs[i] += self.gaussian_pdf(row[j], self.mean_values[i][j], self.std_values[i][j], log_prob)\n",
    "                probs[i] = exp(probs[i])\n",
    "        \n",
    "        else: \n",
    "            for i in range(self.nr_of_classes):\n",
    "                probs[i] = self.prior_class_probs[i]\n",
    "                for j in range(len(row)):\n",
    "                    probs[i] *= self.gaussian_pdf(row[j], self.mean_values[i][j], self.std_values[i][j], log_prob)\n",
    "        \n",
    "        probs = [x / fsum(probs) for x in probs]\n",
    "        prediction = probs.index(max(probs))\n",
    "        return probs, prediction \n",
    "    \n",
    "    def predict(self, test_set, log_prob = False):\n",
    "        X_test = test_set.iloc[:, :-1].values.tolist()\n",
    "        Y_test = test_set.iloc[:, -1].values.tolist()\n",
    "        probabilities = list()\n",
    "        predictions = list()\n",
    "        corrects = 0\n",
    "        cel = 0 # Cross entropy loss\n",
    "        for x, y in zip(X_test, Y_test):\n",
    "            prob, pred = self.pred_row(x, log_prob)\n",
    "            cel += -log(prob[y])\n",
    "            probabilities.append(prob)\n",
    "            predictions.append(pred)\n",
    "            if pred == y:\n",
    "                corrects += 1    \n",
    "        accuracy = corrects / len(Y_test)\n",
    "        return probabilities, accuracy, predictions, cel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembled Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembledNBClassifier():\n",
    "    def __init__(self, nr_of_classes):\n",
    "        self.classifiers = list()\n",
    "        for i in range(nr_of_classes):\n",
    "            self.classifiers.append(NaiveBayesClassifier())\n",
    "    \n",
    "    def fit(self, train_set, seed=None):\n",
    "        self.nr_of_classes=train_set.groupby('class').ngroups\n",
    "        self.nr_of_attributes=len(train_set.iloc[0,:-1])\n",
    "        # Initializing classifiers\n",
    "        for cl in self.classifiers:\n",
    "            bag = train_set.sample(frac=1, replace=True, random_state=seed).reset_index(drop=True)\n",
    "            cl.fit(bag, True, self.nr_of_classes, self.nr_of_attributes)\n",
    "        \n",
    "    \n",
    "    def predict(self, test_set, log_prob = False, majority_vote = False):\n",
    "        # splitting the data\n",
    "        X_test = test_set.iloc[:, :-1].values.tolist()\n",
    "        Y_test = test_set.iloc[:, -1].values.tolist()\n",
    "\n",
    "        corrects = 0 # nr of correct predictions\n",
    "        cel = 0 # Cross entropy loss\n",
    "        for x, y in zip(X_test, Y_test):\n",
    "            preds = list()\n",
    "            probs = list()\n",
    "\n",
    "            for cl in self.classifiers:\n",
    "                prob, pred = cl.pred_row(x, log_prob) # predict each row\n",
    "                preds.append(pred)\n",
    "                probs.append(prob)\n",
    "            if majority_vote:\n",
    "                # Breaking ties with random choice\n",
    "                prediction = max(set(preds), key = lambda x: preds.count(x) + 0.1*random.random())\n",
    "            else:\n",
    "                if log_prob:\n",
    "                    # arithmetic mean\n",
    "                    agg_probs = [fsum(x)/len(probs) for x in zip(*probs)]\n",
    "                else:\n",
    "                    agg_probs = [fsum(x)/len(probs) for x in zip(*probs)]\n",
    "#                     agg_probs = self.nr_of_classes*[1]\n",
    "#                     for i in range(len(probs[0])):\n",
    "#                         for j in range(len(probs)):\n",
    "#                             agg_probs[i] *= probs[j][i]\n",
    "#                         agg_probs[i] = agg_probs[i]**(1/len(probs))\n",
    "                # argmax of the maximum choice\n",
    "                prediction = agg_probs.index(max(agg_probs))\n",
    "                cel += -log(agg_probs[y])\n",
    "            if prediction == y:\n",
    "                corrects += 1\n",
    "                \n",
    "        # count accuracy\n",
    "        accuracy = corrects / len(Y_test)\n",
    "        return accuracy, cel\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with sklearn classifier 0.9333333333333333\n",
      "Accuracy with my classifier with log prob 0.9333333333333333 Cross entropy loss 7.56394488432537\n",
      "Accuracy with my classifier without log prob 0.9333333333333333 Cross entropy loss 7.56394488432537\n",
      "Predictions with sklearn classifier [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 2 2]\n",
      "Predictions with log prob [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 2 2]\n",
      "Predictions without log prob [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 2 2]\n",
      "Values from test set [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2]\n",
      "Accuracy with sklearn ensembled classifier 0.9333333333333333\n",
      "Ensemble accuracy with aggregation 0.9333333333333333 Cross entropy loss 6.843444364366109\n",
      "Ensemble accuracy with log and aggregation 0.9333333333333333 Cross entropy loss 6.843444364366109\n",
      "Accuracy with majority vote 0.9333333333333333\n",
      "Accuracy with log and majority vote 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "train_test_split = 0.8\n",
    "\n",
    "# Shuffle and split data into training 80% and testing 20%\n",
    "train_set = dataset.sample(frac=train_test_split, random_state=seed)\n",
    "test_set = dataset.drop(train_set.index)\n",
    "train_set.reset_index(drop=True, inplace=True)\n",
    "test_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "nbc = NaiveBayesClassifier()\n",
    "nbc.fit(train_set)\n",
    "\n",
    "probabilities, accuracy, preds, cel = nbc.predict(test_set, log_prob=True)\n",
    "preds = np.array(preds)\n",
    "\n",
    "probabilities2, accuracy2, preds2, cel2 = nbc.predict(test_set, log_prob=False)\n",
    "preds2 = np.array(preds2)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train = train_set.iloc[:,:-1].to_numpy()\n",
    "Y_train = train_set.iloc[:,-1].to_numpy().astype('int')\n",
    "X_test = test_set.iloc[:,:-1].to_numpy()\n",
    "Y_test = test_set.iloc[:,-1].to_numpy().astype('int')\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = gnb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy with sklearn classifier\", (Y_test == Y_pred).sum() / len(Y_test))\n",
    "print(\"Accuracy with my classifier with log prob\", accuracy, \"Cross entropy loss\", cel)\n",
    "print(\"Accuracy with my classifier without log prob\", accuracy2, \"Cross entropy loss\", cel2)\n",
    "print(\"Predictions with sklearn classifier\", Y_pred)\n",
    "print(\"Predictions with log prob\", preds)\n",
    "print(\"Predictions without log prob\", preds2)\n",
    "print(\"Values from test set\", Y_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(GaussianNB(), n_estimators=100)\n",
    "\n",
    "bagging.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = bagging.predict(X_test)\n",
    "\n",
    "print(\"Accuracy with sklearn ensembled classifier\", (Y_test == Y_pred).sum() / len(Y_test))\n",
    "\n",
    "ens_nbc = EnsembledNBClassifier(100)\n",
    "ens_nbc.fit(train_set, seed)\n",
    "\n",
    "accuracy, cel = ens_nbc.predict(test_set)\n",
    "print(\"Ensemble accuracy with aggregation\", accuracy, \"Cross entropy loss\", cel)\n",
    "\n",
    "accuracy, cel = ens_nbc.predict(test_set, log_prob=True)\n",
    "print(\"Ensemble accuracy with log and aggregation\", accuracy, \"Cross entropy loss\", cel)\n",
    "\n",
    "accuracy, cel = ens_nbc.predict(test_set, majority_vote=True)\n",
    "print(\"Accuracy with majority vote\", accuracy)\n",
    "\n",
    "accuracy, cel = ens_nbc.predict(test_set, log_prob=True, majority_vote=True)\n",
    "print(\"Accuracy with log and majority vote\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single accuracy 0.9525333333333333\n",
      "Ensemble accuracy 0.9522333333333334\n"
     ]
    }
   ],
   "source": [
    "# Testing 1000 times and see average accuracy with Sklearn\n",
    "\n",
    "n = 1000\n",
    "single_accuracies = list()\n",
    "ensemble_accuracies = list()\n",
    "\n",
    "nr_of_classifiers = 1000\n",
    "\n",
    "for i in range(n):\n",
    "    train_test_split = 0.8\n",
    "\n",
    "    # Shuffle and split data into training 80% and testing 20%\n",
    "    train_set = dataset.sample(frac=train_test_split, random_state=seed)\n",
    "    test_set = dataset.drop(train_set.index)\n",
    "    train_set.reset_index(drop=True, inplace=True)\n",
    "    test_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train = train_set.iloc[:,:-1].to_numpy()\n",
    "    Y_train = train_set.iloc[:,-1].to_numpy().astype('int')\n",
    "    X_test = test_set.iloc[:,:-1].to_numpy()\n",
    "    Y_test = test_set.iloc[:,-1].to_numpy().astype('int')\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = gnb.predict(X_test)\n",
    "\n",
    "    single_accuracies.append((Y_test == Y_pred).sum() / len(Y_test))\n",
    "\n",
    "\n",
    "    bagging = BaggingClassifier(GaussianNB(), n_estimators=nr_of_classifiers)\n",
    "\n",
    "    bagging.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = bagging.predict(X_test)\n",
    "\n",
    "    ensemble_accuracies.append((Y_test == Y_pred).sum() / len(Y_test))\n",
    "\n",
    "    \n",
    "mean_single_accuracy = fsum(single_accuracies) / n\n",
    "\n",
    "mean_ensemble_accuracy = fsum(ensemble_accuracies) / n\n",
    "\n",
    "print(\"Single accuracy\", mean_single_accuracy)\n",
    "print(\"Ensemble accuracy\", mean_ensemble_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single accuracy sklearn 0.9525666666666667\n",
      "Single accuracy with log 0.9528333333333334\n",
      "Single cel with log 4.138827005881541\n",
      "Single accuracy without log 0.9528333333333334\n",
      "Single cel without log 4.138827005881541\n",
      "Ensemble accuracy sklearn 0.9521333333333333\n",
      "Ensemble accuracy 0.9524666666666667\n",
      "Ensemble cel 3.9306941522192274\n",
      "Ensemble accuracy with log 0.9524666666666667\n",
      "Ensemble cel with log 3.9306941522192274\n",
      "Ensemble accuracy with majority vote 0.9525666666666667\n",
      "Ensemble accuracy with log and majority vote 0.9526\n"
     ]
    }
   ],
   "source": [
    "# Testing 100 times and see average accuracy and cel\n",
    "\n",
    "n = 1000\n",
    "\n",
    "nr_of_classifiers = 1000\n",
    "\n",
    "single_accuracies_skl = list()\n",
    "ensemble_accuracies_skl = list()\n",
    "single_accuracies_1 = list()\n",
    "single_accuracies_2 = list()\n",
    "ensemble_accuracies_1 = list()\n",
    "ensemble_accuracies_2 = list()\n",
    "ensemble_accuracies_3 = list()\n",
    "ensemble_accuracies_4 = list()\n",
    "single_cels_1 = list()\n",
    "single_cels_2 = list()\n",
    "ensemble_cels_1 = list()\n",
    "ensemble_cels_2 = list()\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    train_test_split = 0.8\n",
    "\n",
    "    # Shuffle and split data into training 80% and testing 20%\n",
    "    train_set = dataset.sample(frac=train_test_split, random_state=seed)\n",
    "    test_set = dataset.drop(train_set.index)\n",
    "    train_set.reset_index(drop=True, inplace=True)\n",
    "    test_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train = train_set.iloc[:,:-1].to_numpy()\n",
    "    Y_train = train_set.iloc[:,-1].to_numpy().astype('int')\n",
    "    X_test = test_set.iloc[:,:-1].to_numpy()\n",
    "    Y_test = test_set.iloc[:,-1].to_numpy().astype('int')\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = gnb.predict(X_test)\n",
    "\n",
    "    single_accuracies_skl.append((Y_test == Y_pred).sum() / len(Y_test))\n",
    "\n",
    "    nbc = NaiveBayesClassifier()\n",
    "    nbc.fit(train_set)\n",
    "\n",
    "    _, accuracy1, _, cel1 = nbc.predict(test_set, log_prob=True)\n",
    "\n",
    "\n",
    "    _, accuracy2, _, cel2 = nbc.predict(test_set, log_prob=False)\n",
    "\n",
    "\n",
    "    single_accuracies_1.append(accuracy1)\n",
    "    single_accuracies_2.append(accuracy2)\n",
    "    single_cels_1.append(cel1)\n",
    "    single_cels_2.append(cel2)\n",
    "\n",
    "    bagging = BaggingClassifier(GaussianNB(), n_estimators=nr_of_classifiers)\n",
    "\n",
    "    bagging.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = bagging.predict(X_test)\n",
    "\n",
    "    ensemble_accuracies_skl.append((Y_test == Y_pred).sum() / len(Y_test))\n",
    "\n",
    "    ens_nbc = EnsembledNBClassifier(nr_of_classifiers)\n",
    "    ens_nbc.fit(train_set, seed)\n",
    "\n",
    "    accuracy, cel = ens_nbc.predict(test_set)\n",
    "    ensemble_accuracies_1.append(accuracy)\n",
    "    ensemble_cels_1.append(cel)\n",
    "\n",
    "    accuracy, cel = ens_nbc.predict(test_set, log_prob=True)\n",
    "    ensemble_accuracies_2.append(accuracy)\n",
    "    ensemble_cels_2.append(cel)\n",
    "\n",
    "\n",
    "    accuracy, _ = ens_nbc.predict(test_set, majority_vote=True)\n",
    "    ensemble_accuracies_3.append(accuracy)\n",
    "\n",
    "    accuracy, _ = ens_nbc.predict(test_set, log_prob=True, majority_vote=True)\n",
    "    ensemble_accuracies_4.append(accuracy)\n",
    "    \n",
    "\n",
    "\n",
    "mean_single_accuracy_skl = fsum(single_accuracies_skl) / n\n",
    "mean_single_accuracy_1 = fsum(single_accuracies_1) / n\n",
    "mean_single_accuracy_2 = fsum(single_accuracies_2) / n\n",
    "mean_single_cel_1 = fsum(single_cels_1) / n\n",
    "mean_single_cel_2 = fsum(single_cels_2) / n\n",
    "\n",
    "mean_ensemble_accuracy_skl = fsum(ensemble_accuracies_skl) / n\n",
    "mean_ensemble_accuracy_1 = fsum(ensemble_accuracies_1) / n\n",
    "mean_ensemble_accuracy_2 = fsum(ensemble_accuracies_2) / n\n",
    "mean_ensemble_accuracy_3 = fsum(ensemble_accuracies_3) / n\n",
    "mean_ensemble_accuracy_4 = fsum(ensemble_accuracies_4) / n\n",
    "mean_ensemble_cel_1 = fsum(ensemble_cels_1) / n\n",
    "mean_ensemble_cel_2 = fsum(ensemble_cels_2) / n\n",
    "\n",
    "print(\"Single accuracy sklearn\", mean_single_accuracy_skl)\n",
    "print(\"Single accuracy with log\", mean_single_accuracy_1)\n",
    "print(\"Single cel with log\", mean_single_cel_1)\n",
    "print(\"Single accuracy without log\", mean_single_accuracy_2)\n",
    "print(\"Single cel without log\", mean_single_cel_2)\n",
    "print(\"Ensemble accuracy sklearn\", mean_ensemble_accuracy_skl)\n",
    "print(\"Ensemble accuracy\", mean_ensemble_accuracy_1)\n",
    "print(\"Ensemble cel\", mean_ensemble_cel_1)\n",
    "print(\"Ensemble accuracy with log\", mean_ensemble_accuracy_2)\n",
    "print(\"Ensemble cel with log\", mean_ensemble_cel_2)\n",
    "print(\"Ensemble accuracy with majority vote\", mean_ensemble_accuracy_3)\n",
    "print(\"Ensemble accuracy with log and majority vote\", mean_ensemble_accuracy_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.index(max(arr, key=lambda x: random()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import random\n",
    "arr = [0.0000000001, 0.00000000011, 0.0000000002, 0.00000000012, 0.0000000002]\n",
    "max(set(arr), key = lambda x: arr.count(x) + random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
